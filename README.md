# NLP
This research presents some experimental results on the TED Talks 2020 dataset for the task Korean - Vietnamese and Vietnamese - Korean machine translation with the purpose of providing an overview of the dataset and a deep learning machine translation model for the problem.
# Dataset 
In this research, we utilized TED Talks 2020, a small part of one of the largest multilingual datasets (Open Parallel Corpus (OPUS)[https://opus.nlpl.eu/index.php]) to implement several experiments. It contains a crawl of roughly 4,000 TED and TED-X transcripts from July 2020. All the transcripts were translated by a global community of volunteers from English to more than 100 languages. As TED Talks is famous for its vocabulary and context coverage as well as the purpose of this research, in this paper, we employed the Korean-Vietnamese version with the size of 323,525 parallel pairs.
#METHODOLOGIES
Transformer is a a prominent architecture for constructing various state-of-the-art models: GPT-2, GPT-3, BERT, RoBERTa etc. we decide to choose Transformer stemmed from Pytorch to conduct our Korean - Vietnamese machine translation experiments.
